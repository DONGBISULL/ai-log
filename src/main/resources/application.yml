spring:
  application:
    name: ai-log
  kafka:
    bootstrap-servers: localhost:9092 #
    listener:
      ack-mode: manual_immediate
      concurrency: 10  # 동시 처리 스레드 수 증가 (CPU 코어 수에 맞게 조정)
      retry:
        enabled: true
        max-attempts: 3
        backoff:
          interval: 1000
          multiplier: 2.0
          # 배치 처리 설정 추가
          max-poll-records: 100  # 한 번에 가져올 최대 레코드 수
          poll-timeout: 30000    # 폴링 타임아웃 (30초)
    consumer:
      group-id: spring-log-analyzer
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 성능 최적화 설정 추가
      max-poll-records: 100
      fetch-min-size: 50000  # 최소 페치 크기 (50KB)
      fetch-max-wait: 500    # 최대 대기 시간 (500ms)
      properties:
        max.partition.fetch.bytes: 1048576  # 파티션당 최대 페치 크기 (1MB)
        session.timeout.ms: 30000           # 세션 타임아웃
        heartbeat.interval.ms: 3000         # 하트비트 간격
  datasource:
    jdbc-url: jdbc:postgresql://localhost:5432/test-db
    driver-class-name: org.postgresql.Driver
    username: '사용자명'
    password: '비밀번호'
  jpa:
    hibernate:
      ddl-auto: update
    database: postgresql
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
  ai:
    # 올라마
    #    ollama:
    #      base-url: http://localhost:11434
    #      chat:
    #        options:
    #          model: llama3:8b
    #          temperature: 0.7
    #          timeout: 60s
    # 제미나이 (vertex) 유료라 다른 방식으로 수정
    vectorstore:
      pgvector:
        index-type: HNSW # 다층 그래프 생성 쿼리 성능 더 좋음
        distance-type: COSINE_DISTANCE # 검색 거리 설정
        dimensions: 1536 # 임베딩 차원 PgVectorStore 임베딩 열 설정
        max-document-batch-size: 10000 # 단일 배치 처리할 수 있는 문서 최대 수
        schema-validation: true # 스키마 테이블 이름 검증을 통해 유효 객체 확인
        initialize-schema: false # 아무 것도 없을 경우 true 로 설정할 시 자동으로 테이블 생성
        vector-table-name: 'vector_log'
    openai:
      embedding:
        base-url: 'https://generativelanguage.googleapis.com'
        options:
          model: "gemini-embedding-001"
      api-key: 'API키'
      base-url: 'https://generativelanguage.googleapis.com/v1beta/openai'
      chat:
        completions-path: /chat/completions
        options:
          model: gemini-2.0-flash
    enabled: true
server:
  port: 8084
  tomcat:
    connection-timeout: 300000
log-processing:
  limit-size: 100

